{
	"The model which will generate the completion. Some models are suitable for natural language tasks, others specialize in code." : "Das Modell, das die Vervollständigung generiert. Einige Modelle eignen sich für Aufgaben in natürlicher Sprache, andere sind auf Code spezialisiert.",
	"Controls randomness: Lowering results in less random completions. As the temperature approaches zero, the node will become deterministic and repetitive." : "Steuert die Zufälligkeit: Das Verringern führt zu weniger zufälligen Abschlüssen. Wenn sich die Temperatur Null nähert, wird der Knoten deterministisch und repetitiv.",
	"The maximum number of tokens to generate in the completion." : "Die maximale Anzahl von Token, die bei der Fertigstellung generiert werden sollen.",
	"Up to four sequences where the API will stop generating further tokens. The returned text will not contain the stop sequence." : "Bis zu vier Sequenzen, in denen die API keine weiteren Token mehr generiert. Der zurückgegebene Text enthält die Stoppsequenz nicht.",
	"An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass.": "Eine Alternative zur Probenahme mit Temperatur, genannt Kernprobenahme, bei der das Modell die Ergebnisse der Token mit top_p Wahrscheinlichkeitsmasse berücksichtigt.",
	"For using ChatGPT you should get an API key." : "Für die Verwendung von ChatGPT sollten Sie einen API-Schlüssel erhalten.",
	"Create API keys and copy in this field." : "Erstellen Sie API-Schlüssel und kopieren Sie sie in dieses Feld.",
	"ChatGPT: Optimizing Language Models for Dialogue" : "ChatGPT: Optimierung von Sprachmodellen für den Dialog",
	"Go to" : "Navigieren Sie zu",
	"Submit" : "Senden",
	"Clear" : "Reinigen",
	"Reconfigure" : "Rekonfiguriert",
	"Save" : "Speichern",
	"Loading..." : "Laden...",
	"Model" : "Modell",
	"Maximum length" : "Maximallänge",
	"Temperature" : "Temperatur",
	"Stop sequences" : "Stoppsequenzen",
	"This model's maximum context length is" : "Die maximale Kontextlänge dieses Modells beträgt",
	"tokens, however you requested" : "Token, Sie haben jedoch",
	"tokens (" : "Token angefordert (",
	"in your prompt;" : "in Ihrer Eingabeaufforderung;",
	"for the completion). Please reduce your prompt; or completion length." : "für die Vervollständigung). Bitte reduzieren Sie Ihre Aufforderung; oder Abschlusslänge."
}